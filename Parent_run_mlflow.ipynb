{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536c4cf3",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc586d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from scipy import stats \n",
    "from scipy.stats import expon, reciprocal\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfa6c6",
   "metadata": {},
   "source": [
    "Start the MLflow tracking server by\n",
    "\n",
    "mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0\n",
    "    --port 5000\n",
    "or use the default storage method to write to mlruns/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e1d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "remote_server_uri = \"http://0.0.0.0:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7a4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/01/27 21:37:39 INFO mlflow.tracking.fluent: Experiment with name 'Housing_value_prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlruns/4', experiment_id='4', lifecycle_stage='active', name='Housing_value_prediction', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"Housing_value_prediction\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a39b938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://0.0.0.0:5000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e82ac5",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fcc4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = \"datasets/housing\"\n",
    "HOUSING_URL = DOWNLOAD_ROOT + HOUSING_PATH + \"/housing.tgz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d100674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to: mlruns/4/8a54430db92c4d63b6563276a3d11811/artifacts\n",
      "final_rmse: 19128.562647984956\n",
      "final_mae: 12316.385085594316\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    with mlflow.start_run(run_name=\"PARENT RUN\",nested=True) as parent_run:\n",
    "    \n",
    "\n",
    "        def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "            if not os.path.isdir(housing_path):\n",
    "                os.makedirs(housing_path)\n",
    "            tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "            urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "            housing_tgz = tarfile.open(tgz_path)\n",
    "            housing_tgz.extractall(path=housing_path)\n",
    "            housing_tgz.close()\n",
    "\n",
    "#loading the dataset\n",
    "\n",
    "        def load_housing_data(housing_path=HOUSING_PATH):\n",
    "            csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "            return pd.read_csv(csv_path)\n",
    "\n",
    "#startified splitting\n",
    "\n",
    "        def strat_split():\n",
    "            fetch_data = fetch_housing_data()\n",
    "            housing = load_housing_data()\n",
    "            housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "            housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "    \n",
    "            split = StratifiedShuffleSplit(n_splits=1,test_size=0.2 ,random_state=42)\n",
    "            for train_index, test_index in split.split(housing,housing[\"income_cat\"]):\n",
    "                strat_train_set = housing.loc[train_index]\n",
    "                strat_test_set = housing.loc[test_index]\n",
    "            # droping income_cat column from the splitted datasets to return to original form\n",
    "            for set in (strat_train_set, strat_test_set):\n",
    "                set.drop([\"income_cat\"], axis=1, inplace=True)\n",
    "            return strat_train_set,strat_test_set\n",
    "\n",
    "        #seprating target variables and predictors\n",
    "        def label_seprate():\n",
    "            strat_train_set,strat_test_set = strat_split()\n",
    "            housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "            housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "            return housing,housing_labels\n",
    "\n",
    "        housing,housing_labels = label_seprate()\n",
    "\n",
    "        def dtype_seprate():\n",
    "            # getting the numerical and categorical columns\n",
    "    \n",
    "            #housing,housing_labels = label_seprate()\n",
    "\n",
    "            num_cols = housing.select_dtypes(include=np.number).columns\n",
    "            cat_cols = housing.select_dtypes(exclude=np.number).columns\n",
    "    \n",
    "            return num_cols,cat_cols\n",
    "\n",
    "        #Generating attributes\n",
    "\n",
    "        col_names = \"total_rooms\", \"total_bedrooms\", \"population\", \"households\"\n",
    "        rooms_ix, bedrooms_ix, population_ix, households_ix = [housing.columns.get_loc(c) for c in col_names]\n",
    "\n",
    "        class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "                def __init__(self, add_bedrooms_per_room=True): # no *args or **kargs\n",
    "                    self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "                def fit(self, X, y=None):\n",
    "                    return self  # nothing else to do\n",
    "                def transform(self, X):\n",
    "                    rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "                    population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "                    if self.add_bedrooms_per_room:\n",
    "                        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "                        return np.c_[X, rooms_per_household, population_per_household,\n",
    "                                 bedrooms_per_room]\n",
    "                    else:\n",
    "                        return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "        #Pipeline\n",
    "\n",
    "        def pipe():\n",
    "            with mlflow.start_run(run_name = \"pipline\",nested=True):\n",
    "        \n",
    "                num_cols,cat_cols = dtype_seprate()\n",
    "        \n",
    "                num_pipeline = Pipeline(\n",
    "                [(\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                 (\"attribs_adder\",CombinedAttributesAdder()),\n",
    "                 (\"std_scaler\", StandardScaler())\n",
    "                ])\n",
    "    \n",
    "                num_attribs = list(housing[num_cols])\n",
    "                cat_attribs = [\"ocean_proximity\"]\n",
    "    \n",
    "                full_pipeline = ColumnTransformer(\n",
    "                [ (\"num\",num_pipeline,num_attribs),\n",
    "                  (\"cat\",OneHotEncoder(),cat_attribs),\n",
    "                ])\n",
    "        \n",
    "                housing_prepared = full_pipeline.fit_transform(housing)\n",
    "        \n",
    "                mlflow.log_param(key=\"imputer\",value=full_pipeline.transformers_[0][1].named_steps[\"imputer\"].get_params())\n",
    "                mlflow.log_param(key=\"custom_transformer\",value=full_pipeline.transformers_[0][1].named_steps[\"attribs_adder\"].get_params())\n",
    "                mlflow.log_param(key=\"Standardiser\",value=full_pipeline.transformers_[0][1].named_steps[\"std_scaler\"].get_params())\n",
    "                mlflow.log_param(key=\"OneHotEncoder\",value=full_pipeline.transformers_[1][1].get_params())\n",
    "                print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "                mlflow.end_run()\n",
    "        \n",
    "                return housing_prepared\n",
    "        \n",
    "        housing_prepared=pipe()\n",
    "        \n",
    "        def eval_metrics(actual, pred):\n",
    "            # compute relevant metrics\n",
    "            rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "            mae = mean_absolute_error(actual, pred)\n",
    "            \n",
    "            return rmse, mae\n",
    "        \n",
    "        #Linear Regressor func\n",
    "        def lin_reg():\n",
    "            with mlflow.start_run(run_name=\"LinearReg\",nested=True):\n",
    "        \n",
    "                lin_reg = LinearRegression()\n",
    "    \n",
    "                lin_reg.fit(housing_prepared, housing_labels)\n",
    "                housing_predictions = lin_reg.predict(housing_prepared)\n",
    "        \n",
    "                (rmse,mae)=eval_metrics(housing_labels,housing_predictions)\n",
    "        \n",
    "                # Log parameter, metrics, and model to MLflow\n",
    "                mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "                mlflow.log_metrics({\"mae\": mae})\n",
    "                return LinearRegression()\n",
    "        \n",
    "        lin_reg()\n",
    "            \n",
    "        #Tree Regressor func\n",
    "        def tree_reg():\n",
    "            with mlflow.start_run(run_name=\"DecisionTree\",nested=True):\n",
    "                tree_reg= DecisionTreeRegressor(random_state=42)\n",
    "        \n",
    "                mlflow.log_param(key=\"random state\",value=tree_reg.random_state)\n",
    "        \n",
    "                tree_reg.fit(housing_prepared, housing_labels)\n",
    "                housing_predictions = tree_reg.predict(housing_prepared)\n",
    "        \n",
    "                (rmse,mae)=eval_metrics(housing_labels,housing_predictions)\n",
    "        \n",
    "                #Log parameter, metrics, and model to MLflow\n",
    "            \n",
    "                mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "                mlflow.log_metrics({\"mae\": mae})\n",
    "                mlflow.end_run()\n",
    "                return tree_reg\n",
    "            \n",
    "        tree_reg()\n",
    "            \n",
    "        #Forest Regressor func\n",
    "        \n",
    "        def forest_reg():\n",
    "            with mlflow.start_run(run_name=\"RandomForest\",nested=True):\n",
    "                forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        \n",
    "                forest_reg.fit(housing_prepared, housing_labels)\n",
    "                housing_predictions = forest_reg.predict(housing_prepared)\n",
    "        \n",
    "                (rmse,mae)=eval_metrics(housing_labels,housing_predictions)\n",
    "        \n",
    "                #Log parameter, metrics, and model to MLflow\n",
    "        \n",
    "                mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "                mlflow.log_metrics({\"mae\": mae})\n",
    "                mlflow.log_params({\"n_estimators\":forest_reg.n_estimators,\"random state\":forest_reg.random_state})\n",
    "                mlflow.end_run()\n",
    "                return forest_reg\n",
    "            \n",
    "        forest_reg()\n",
    "            \n",
    "        #SVM regressor\n",
    "        def svm_reg():\n",
    "            with mlflow.start_run(run_name=\"SVR\",nested=True):\n",
    "                svm_reg= SVR(kernel=\"linear\")\n",
    "        \n",
    "                svm_reg.fit(housing_prepared, housing_labels)\n",
    "                housing_predictions = svm_reg.predict(housing_prepared)\n",
    "        \n",
    "                (rmse,mae)=eval_metrics(housing_labels,housing_predictions)\n",
    "        \n",
    "                #Log parameter, metrics, and model to MLflow\n",
    "        \n",
    "                mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "                mlflow.log_metrics({\"mae\": mae})\n",
    "                mlflow.log_param(key=\"kernel\",value=svm_reg.kernel)\n",
    "                mlflow.end_run()\n",
    "                return svm_reg\n",
    "            \n",
    "        svm_reg()\n",
    "        \n",
    "        #Cross Validation\n",
    "        def cross_val(reg_model):\n",
    "            with mlflow.start_run(run_name=\"cross_val\",nested=True):\n",
    "                scores = cross_val_score(reg_model, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        \n",
    "                rmse_scores = np.sqrt(-scores)\n",
    "                mlflow.log_params({\"scores\":rmse_scores,\"model\":type(reg_model)})\n",
    "                mlflow.log_metrics({\"Mean\":rmse_scores.mean(),\"Standard deviation\":rmse_scores.std()})\n",
    "        \n",
    "                mlflow.end_run()\n",
    "        \n",
    "                return scores\n",
    "        \n",
    "        cross_val(lin_reg())\n",
    "        cross_val(forest_reg())\n",
    "        \n",
    "        #GridSearch CV\n",
    "        def grid_search_cv(reg_model):\n",
    "            with mlflow.start_run(run_name=\"grid_searvh_cv\",nested=True):\n",
    "        \n",
    "                param_grid = [\n",
    "                    # try 12 (3×4) combinations of hyperparameters\n",
    "                    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "                    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "                    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "                    ]\n",
    "        \n",
    "                grid_search = GridSearchCV(reg_model, param_grid, cv=5,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   return_train_score=True)\n",
    "                mlflow.log_params({\"parameters\":param_grid,\"model\":type(reg_model),\"scoring\":grid_search.scoring})\n",
    "        \n",
    "                mlflow.end_run()\n",
    "                return grid_search\n",
    "        \n",
    "        \n",
    "        \n",
    "        grid_search = grid_search_cv(forest_reg())\n",
    "        grid_search.fit(housing_prepared, housing_labels)\n",
    "        \n",
    "        def final_model(best_estimator):\n",
    "            with mlflow.start_run(run_name=\"Final_model\",nested=True):\n",
    "                final_model = best_estimator\n",
    "        \n",
    "                final_prediction = final_model.predict(housing_prepared)\n",
    "        \n",
    "                (rmse,mae)=eval_metrics(housing_labels,final_prediction)\n",
    "                mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "                mlflow.log_metrics({\"mae\": mae})\n",
    "                mlflow.end_run()\n",
    "                print(\"final_rmse: {}\".format(rmse))\n",
    "                print(\"final_mae: {}\".format(mae))\n",
    "                \n",
    "        final_model(grid_search.best_estimator_)\n",
    "        \n",
    "        mlflow.end_run()\n",
    "        \n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc39fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a515a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
